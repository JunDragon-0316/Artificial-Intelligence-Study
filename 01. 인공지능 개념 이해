## 학습목표
- 코드와 시각적으로 딥러닝 이해
- 깊게 들어가는 이론은 없으니 먼저 쭉 따라 해보는이론 공부 
- 기본 CNN과 간단한 프로젝트도 돌릴 수 있을 정도의 수준

#### **딥러닝 전체 구조**
# Data -> Model -> Logit -> Result
#    (Up)Optm <-(Down) Loss

### Data
- 학습 시키기 위한 데이터. 이데이터가 모델에 들어감
- 데이터가 생성되고, 데이터에 Transform 변형을 준다거나 모델에 들어가기 전에 데이터 전처리가 들어감
- 이 떄 들어갈 떄는 Batch 로 만들어서 Model에 넣어줌

### Model = CNN
- LeNet, AlexNet, VGG 나 ResNet 등 다양하게 설계된 모델
- Convolution Layer, Pooling 등 다양한 Layer 층들로 구성
- 이 모델 안에 학습 파라미터가 있고, 이 모델이 학습하는 대상
- 특징을 뽑아내고 예측을 하는 모든 측정이 이루어짐.

## Layer
- Deep learning = 여러층으로 이루어진 Layer
- Input layer, Hidden layers, Output layer 로 구성

## Convolution (CNN 중 C에 해당)
- input image, Convolution Kornel, Feature map 으로 구성
- 합성법 [ 이미지 + 필터를 계산해서 테두리를 잡아주는 방식 ]
- 필터에 따른 방식이 다양

## Weight/ Filter / Kernel / Variable / Bias
- Visualize Learned Weights
- Weight = 목적에 따른 학습하려는 대상
- Filter = 계산을 통해 더좋은 필터를 구분

## Pooling Layer
- Convolved feature 특직을 뽑는 다분화된 데이터 값을
- Polled feature 쪼개서 값을 압축해서 줄여줌

## Activation Function
- Sigmoid
- tanh
- ReLU *(불필요한 부분 제거)
- Leaky ReLU
- Maxout
- ELU

## Softmax
- 최종 마지막 예측값
- LOGITS SCORES, SOFTMAX , PROBABILITIES
- Class 간 값을 유도함 (확률)

### Prediction / Logit
- [0.15, 0.3, 0.2, 0.25]
- 각 Class 별로 예측한 값.
- 여기서 가장 높은 값이 모델이 예상하는 Class 또는 정답

-[0.0, 0.0, 0.0, 1.0, 0.0]
- 위의 숫자가 정답이라고 할 떄 얼마나 틀렸는지 얼마나 맞았는지 확인 가능

### Loss/ Cost / Loss Function
- 예측한 값과 정답과 비굫서 얼마나 틀렸는지를 확인.
- Cross Entropy 등 다양한 Loss Function들이 있음
- 이 떄 계산을 통해 나오는 값이 Loss(Cost, Cost Value 등)이라고 불림
- 이 Loss는 "얼마나 틀렸는지"를 말하며 이 값을 최대한 줄여 나가는 것이 학습의 과정

### Optimization
- 앞에서 얻은 Loss 값을 최소화하기 위해 기울기를 받아 최적화된 Variable 값들로 변환
- 이 반환된 값이 적용된 모델은 바로 전에 돌렸을 때의 결과보다 더 나아지게 됨
- 이 때 바로 최적화된 값만큼 바로 움직이는 것이 아닌 Learning Rate만큼 움직인 값이 적용

##  Learning Rate
- Too low, Just right, Too High
- 사람이 직접 조정해야 되는 부분

## Batch Size
- MNIST 60000개
- 한번에 데이터 삽입 불가
- 데이터 입력값 조정

## Epoch / Step
- 인공지능 반복 작업 

## Train / Validation / Test 
- 

## Label / Graound Truth
- 데이터 Set의 정답


### Result 
- 평가 할 때 또는 예측된 결과를 확인 할 떄는 예측된 값에서 argmax 를 통해 가장 높은 값을 예측한 class라고 둠
- [0.15, 0.3, 0.2, 0.25, 0.1]
- 위의 예측값에서 0.2가 제일 높은 값이므로 클래스 2가 가장 높다고 봄 

### CNN ( Feature Extraction / Classification )
- Convolution + ReLU + Max pooling = 특징을 추출 
- Fully connecter Layer = 결정
- ex) 00 의 패턴 , 모양  
- Max pooling (Polling Layer) - 가장큰 특징을 압축
- Activation Function(ReLU) - 불필요한 부분 제거
- Fully Connected -  계산을 통해 예측
- LeNet / ResNet / DenseNet / AlexNet / VGG16 등을 통해 실행
